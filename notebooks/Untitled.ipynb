{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liable-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.16 ðŸš€ Python-3.8.5 torch-1.7.1 CPU\n",
      "Setup complete âœ… (8 CPUs, 16.0 GB RAM, 354.6/465.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pressed-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module torch.serialization:\n",
      "\n",
      "load(f, map_location=None, pickle_module=<module 'pickle' from '/Users/jorge/anaconda/envs/fun/lib/python3.8/pickle.py'>, **pickle_load_args)\n",
      "    Loads an object saved with :func:`torch.save` from a file.\n",
      "    \n",
      "    :func:`torch.load` uses Python's unpickling facilities but treats storages,\n",
      "    which underlie tensors, specially. They are first deserialized on the\n",
      "    CPU and are then moved to the device they were saved from. If this fails\n",
      "    (e.g. because the run time system doesn't have certain devices), an exception\n",
      "    is raised. However, storages can be dynamically remapped to an alternative\n",
      "    set of devices using the :attr:`map_location` argument.\n",
      "    \n",
      "    If :attr:`map_location` is a callable, it will be called once for each serialized\n",
      "    storage with two arguments: storage and location. The storage argument\n",
      "    will be the initial deserialization of the storage, residing on the CPU.\n",
      "    Each serialized storage has a location tag associated with it which\n",
      "    identifies the device it was saved from, and this tag is the second\n",
      "    argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``\n",
      "    for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.\n",
      "    :attr:`map_location` should return either ``None`` or a storage. If\n",
      "    :attr:`map_location` returns a storage, it will be used as the final deserialized\n",
      "    object, already moved to the right device. Otherwise, :func:`torch.load` will\n",
      "    fall back to the default behavior, as if :attr:`map_location` wasn't specified.\n",
      "    \n",
      "    If :attr:`map_location` is a :class:`torch.device` object or a string containing\n",
      "    a device tag, it indicates the location where all tensors should be loaded.\n",
      "    \n",
      "    Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags\n",
      "    appearing in the file (keys), to ones that specify where to put the\n",
      "    storages (values).\n",
      "    \n",
      "    User extensions can register their own location tags and tagging and\n",
      "    deserialization methods using :func:`torch.serialization.register_package`.\n",
      "    \n",
      "    Args:\n",
      "        f: a file-like object (has to implement :meth:`read`, :meth`readline`, :meth`tell`, and :meth`seek`),\n",
      "            or a string or os.PathLike object containing a file name\n",
      "        map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage\n",
      "            locations\n",
      "        pickle_module: module used for unpickling metadata and objects (has to\n",
      "            match the :attr:`pickle_module` used to serialize file)\n",
      "        pickle_load_args: (Python 3 only) optional keyword arguments passed over to\n",
      "            :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,\n",
      "            :attr:`errors=...`.\n",
      "    \n",
      "    .. warning::\n",
      "        :func:`torch.load()` uses ``pickle`` module implicitly, which is known to be insecure.\n",
      "        It is possible to construct malicious pickle data which will execute arbitrary code\n",
      "        during unpickling. Never load data that could have come from an untrusted\n",
      "        source, or that could have been tampered with. **Only load data you trust**.\n",
      "    \n",
      "    .. note::\n",
      "        When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors\n",
      "        will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``\n",
      "        and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.\n",
      "    \n",
      "    .. note::\n",
      "        By default, we decode byte strings as ``utf-8``.  This is to avoid a common error\n",
      "        case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``\n",
      "        when loading files saved by Python 2 in Python 3.  If this default\n",
      "        is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how\n",
      "        these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them\n",
      "        to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them\n",
      "        as byte arrays which can be decoded later with ``byte_array.decode(...)``.\n",
      "    \n",
      "    Example:\n",
      "        >>> torch.load('tensors.pt')\n",
      "        # Load all tensors onto the CPU\n",
      "        >>> torch.load('tensors.pt', map_location=torch.device('cpu'))\n",
      "        # Load all tensors onto the CPU, using a function\n",
      "        >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
      "        # Load all tensors onto GPU 1\n",
      "        >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
      "        # Map tensors from GPU 1 to GPU 0\n",
      "        >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
      "        # Load tensor from io.BytesIO object\n",
      "        >>> with open('tensor.pt', 'rb') as f:\n",
      "                buffer = io.BytesIO(f.read())\n",
      "        >>> torch.load(buffer)\n",
      "        # Load a module with 'ascii' encoding for unpickling\n",
      "        >>> torch.load('module.pt', encoding='ascii')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banner-alignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class YOLO in module ultralytics.yolo.engine.model:\n",
      "\n",
      "class YOLO(builtins.object)\n",
      " |  YOLO(model='yolov8n.yaml', type='v8') -> None\n",
      " |  \n",
      " |  YOLO\n",
      " |  \n",
      " |  A python interface which emulates a model-like behaviour by wrapping trainers.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, source=None, stream=False, verbose=False, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, model='yolov8n.yaml', type='v8') -> None\n",
      " |      Initializes the YOLO object.\n",
      " |      \n",
      " |      Args:\n",
      " |          model (str, Path): model to load or create\n",
      " |          type (str): Type/version of models to use. Defaults to \"v8\".\n",
      " |  \n",
      " |  export(self, **kwargs)\n",
      " |      Export model.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs : Any other args accepted by the predictors. To see all args check 'configuration' section in docs\n",
      " |  \n",
      " |  fuse(self)\n",
      " |  \n",
      " |  info(self, verbose=False)\n",
      " |      Logs model info.\n",
      " |      \n",
      " |      Args:\n",
      " |          verbose (bool): Controls verbosity.\n",
      " |  \n",
      " |  predict(self, source=None, stream=False, verbose=False, **kwargs)\n",
      " |      Perform prediction using the YOLO model.\n",
      " |      \n",
      " |      Args:\n",
      " |          source (str | int | PIL | np.ndarray): The source of the image to make predictions on.\n",
      " |                        Accepts all source types accepted by the YOLO model.\n",
      " |          stream (bool): Whether to stream the predictions or not. Defaults to False.\n",
      " |          verbose (bool): Whether to print verbose information or not. Defaults to False.\n",
      " |          **kwargs : Additional keyword arguments passed to the predictor.\n",
      " |                     Check the 'configuration' section in the documentation for all available options.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (dict): The prediction results.\n",
      " |  \n",
      " |  reset(self)\n",
      " |      Resets the model modules.\n",
      " |  \n",
      " |  to(self, device)\n",
      " |      Sends the model to the given device.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (str): device\n",
      " |  \n",
      " |  train(self, **kwargs)\n",
      " |      Trains the model on a given dataset.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs (Any): Any number of arguments representing the training configuration.\n",
      " |  \n",
      " |  val(self, data=None, **kwargs)\n",
      " |      Validate a model on a given dataset .\n",
      " |      \n",
      " |      Args:\n",
      " |          data (str): The dataset to validate on. Accepts all formats accepted by yolo\n",
      " |          **kwargs : Any other args accepted by the validators. To see all args check 'configuration' section in docs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  names\n",
      " |      Returns class names of the loaded model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.loa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
